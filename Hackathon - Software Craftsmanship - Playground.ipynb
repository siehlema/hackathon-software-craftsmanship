{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hackathon - Software Craftsmanship\n",
        "\n",
        "In diesem Notebook findet ihr alle Übungen mit relevanten Infos zum Schülerstipendium Hackathon mit dem Thema Software Craftsmanship am 20.11.2024.\n",
        "\n",
        "## Allgemeine Infos\n",
        "\n",
        "* Alle Übungsaufgaben zum Hackathon findet ihr hier. Wann welche Übung bearbeitet werden soll wird im Zuge der Präsentation klar.\n",
        "* Führt die Übungen soweit möglich im Google Colab aus. Wir können zwischendurch gerne diskutieren, wie eine Lösung in euerer IDE aussehen kann.\n",
        "* Es gibt zwei optionale Übungen. Diese könnt ihr bearbeiten, wenn ihr mit der jeweils anderen Aufgabe schneller fertig seid.\n",
        "* Denkt bei jeder Übung daran diese am Ende auch in euren Team-Branch zu mergen. Etwas Zeit dafür einplanen!\n",
        "* Bei Fragen fragt einfach unkompliziert bei uns nach\n",
        "\n",
        "Ansonsten: Viel Spaß :)"
      ],
      "metadata": {
        "id": "22eSGJsPccwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Übung 1 - Google Colab IDE und Git\n",
        "\n",
        "* Schaut euch in diesem Notebook um\n",
        "* Was kann man hier so machen?\n",
        "* Erzeugt Text- und Code-Blöcke und führt diese aus.\n",
        "* Legt in Github einen Übungsbranch an. Speichert Changes (CTRL+S) und wählt den Übungsbranch aus. Seht euch die Changes in Github im Branch an.\n",
        "* Mergt diesen Branch über Github danach in euren Team-Branch"
      ],
      "metadata": {
        "id": "lpxU-lrMcxaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Colab Notebook Tipps\n",
        "\n",
        "* es gibt Code und Textblöcke\n",
        "* Codeblöcke könnt ihr ausführen, wenn ihr auf den Pfeil links vom Block klickt (oder schneller per CTRL+Enter)\n",
        "* Die Ausgabe wird per Default nach der Ausführung unter dem Codeblock dargestellt.\n",
        "* in Textblöcken kann man Text im Markdown Style formattieren\n",
        "* Codeblöcke sind per Default Python Code Blöcke. Man kann also direkt mit Coding loslegen.\n",
        "* Alternativ kann man in Codeblöcken auch Command Line Commands ausführen. Dazu ein `!` an den Anfang stellen.\n",
        "* schreibt man das Command `%%writefile <Dateiname>` an den Anfang eines Python Codeblocks wird der Block als Datei abgespeichert und der Python Code selbst wird NICHT ausgeführt"
      ],
      "metadata": {
        "id": "3q1ki7pujLO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Übung 2 - Testing\n",
        "\n",
        "* erstellt einen neuen Übungsbranch\n",
        "* im Code-Block unten findet ihr die `AnnoyedToDoList`\n",
        "* schaut euch die Klasse an und führt die Beispielfunktionalität aus\n",
        "* zum Python-Testing findet ihr unten eine Erklärung mit Beispiel\n",
        "* Übungen:\n",
        "  1. teste die Funktion `add_task` mit einer Testfunktion in einer neuen Testdatei und mit passenden Assertions\n",
        "  1. die Methode `delete_task` hat noch keine Implementierung\n",
        "    * implementiere die Logik und schreibt einen Test dazu\n",
        "    * verfolge gerne die Vorgehensweise des TDD\n",
        "* mergt den Übungsbranch danach wieder in euren Teambranch"
      ],
      "metadata": {
        "id": "Q54SG7Xgdvpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the following command writes the code to an external file\n",
        "%%writefile annoyed_todo_list.py\n",
        "\"\"\" Doc String of this module\"\"\"\n",
        "from typing import List\n",
        "\n",
        "def get_external_tasks():\n",
        "    \"\"\"\n",
        "    get external tasks\n",
        "    \"\"\"\n",
        "    # don't implement this!\n",
        "    # this function mocks the response of an external data source\n",
        "    return []\n",
        "\n",
        "class Task:\n",
        "    \"\"\" DocString\"\"\"\n",
        "    task_name: str\n",
        "    done: bool\n",
        "    def print1(self):\n",
        "      \"\"\"Prints 1\"\"\"\n",
        "      print(1)\n",
        "    def print2(self):\n",
        "      \"\"\" print 2\"\"\"\n",
        "      print(2)\n",
        "\n",
        "class AnnoyedToDoList:\n",
        "    \"\"\" DosString\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Konstruktor\"\"\"\n",
        "        self.tasks: List[Task] = []\n",
        "        self.unfinished_tasks = 0\n",
        "\n",
        "    def add_task(self, task_name):\n",
        "        \"\"\"\n",
        "        Function that adds a task to the task list\n",
        "        \"\"\"\n",
        "        if len(self.tasks) > 2:\n",
        "            print(\"Woah! That's a lot of tasks! Ever heard of work-life balance? Not doing this ..\")\n",
        "            return\n",
        "        print(\"Yeah, alright. This time I'll add it to the list ...\")\n",
        "        new_task = Task()\n",
        "        new_task.task_name = task_name\n",
        "        new_task.done = False\n",
        "        self.tasks.append(new_task)\n",
        "        print(f\"Task '{task_name}' added.\")\n",
        "        self.unfinished_tasks += 1\n",
        "\n",
        "    def complete_task(self, task_name):\n",
        "        \"\"\" mark task as complete\"\"\"\n",
        "        for task in self.tasks:\n",
        "            if task.task_name == task_name and not task.done:\n",
        "                task.done = True\n",
        "                self.unfinished_tasks -= 1\n",
        "                print(f\"Task '{task_name}' completed.\")\n",
        "                if self.unfinished_tasks == 0:\n",
        "                    print(\"Wow! You finished all your tasks. Are you sure you're not a robot?\")\n",
        "                return\n",
        "        print(f\"Task '{task_name}' not found or already completed.\")\n",
        "\n",
        "    def show_tasks(self):\n",
        "        \"\"\" Print all tasks\"\"\"\n",
        "\n",
        "        if len(self.tasks) == 0:\n",
        "            print(\"Nothing to do! Go binge-watch a show or something.\")\n",
        "        else:\n",
        "            for i, task in enumerate(self.tasks):\n",
        "                status = \"Done\" if task.done is True else \"Not Done\"\n",
        "                print(f\"{i+1}. {task.task_name} - {status}\")\n",
        "\n",
        "    def delete_task(self, task_name):\n",
        "        \"\"\" Delete a task by name\"\"\"\n",
        "        # the annoyed todo list does not want to delete your task\n",
        "        # time for you to impl this functionality + test in Übung 2\n",
        "        for t in self.tasks:\n",
        "          if t.task_name == task_name:\n",
        "            self.tasks.remove(t)\n",
        "            return t.task_name\n",
        "\n",
        "\n",
        "    def clear_tasks(self):\n",
        "        \"\"\"Delete all tasks\"\"\"\n",
        "        self.tasks.clear()\n",
        "        print(\"All tasks cleared! Now you're free... or are you?\")\n",
        "\n",
        "    def import_tasks_from_external(self):\n",
        "        \"\"\"Imports tasks from an external source\"\"\"\n",
        "\n",
        "        external_tasks = get_external_tasks()\n",
        "        for task in external_tasks:\n",
        "            self.add_task(task)\n",
        "        print(f\"Imported {len(external_tasks)} tasks from external source.\")\n"
      ],
      "metadata": {
        "id": "LK1ZxIQhzyXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b7b505-78db-40b1-d48d-db85149a265e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting annoyed_todo_list.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visit this site\n",
        "http://10.81.253.175:8000/\n"
      ],
      "metadata": {
        "id": "jZApms_146fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from annoyed_todo_list import AnnoyedToDoList\n",
        "\n",
        "# Example usage\n",
        "todo_list = AnnoyedToDoList()\n",
        "todo_list.add_task(\"Buy groceries\")\n",
        "todo_list.add_task(\"Clean the house\")\n",
        "todo_list.show_tasks()\n",
        "todo_list.complete_task(\"Buy groceries\")\n",
        "todo_list.show_tasks()\n",
        "todo_list.clear_tasks()\n",
        "todo_list.import_tasks_from_external()"
      ],
      "metadata": {
        "id": "zixbhILjHg9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4243dd96-faba-49b9-f228-5ab8397ff746"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yeah, alright. This time I'll add it to the list ...\n",
            "Task 'Buy groceries' added.\n",
            "Yeah, alright. This time I'll add it to the list ...\n",
            "Task 'Clean the house' added.\n",
            "1. Buy groceries - Not Done\n",
            "2. Clean the house - Not Done\n",
            "Task 'Buy groceries' completed.\n",
            "1. Buy groceries - Done\n",
            "2. Clean the house - Not Done\n",
            "All tasks cleared! Now you're free... or are you?\n",
            "Imported 0 tasks from external source.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to: Testing in Python\n",
        "\n",
        "Zum Testen verwenden wir das Standard Python Testing-Tool `pytest`."
      ],
      "metadata": {
        "id": "EVzLzj5mq3oS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir brauchen einen Beispieltest, den wir ausführen können. Dazu folgender Python Code, welcher nach Ausführung als Datei abgespeichert wird."
      ],
      "metadata": {
        "id": "b3_EMM_8gGXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile testing_example.py\n",
        "def test_my_stuff_fails():\n",
        "    assert 42 == 43\n",
        "\n",
        "def test_my_stuff_success():\n",
        "    assert 42 == 42"
      ],
      "metadata": {
        "id": "TkHa-3p_zlzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ac0b6a-6c9d-4485-fa9f-96bc7759be33"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting testing_example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Ausführung von `pytest` lässt sich ganz einfach per `!pytest <Dateiname>` starten."
      ],
      "metadata": {
        "id": "k2OrsXX0sC5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest testing_example.py"
      ],
      "metadata": {
        "id": "DKIPhzEPkH1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381c81a1-3005-40f7-ba27-af1003acbf5f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 2 items                                                                                  \u001b[0m\n",
            "\n",
            "testing_example.py \u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                                        [100%]\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_______________________________________ test_my_stuff_fails ________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_my_stuff_fails\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m \u001b[94m42\u001b[39;49;00m == \u001b[94m43\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert 42 == 43\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtesting_example.py\u001b[0m:2: AssertionError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m testing_example.py::\u001b[1mtest_my_stuff_fails\u001b[0m - assert 42 == 43\n",
            "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.12s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests_uebung2.py\n",
        "from annoyed_todo_list import AnnoyedToDoList\n",
        "\n",
        "def add_functions(t):\n",
        "  t.add_task(\"Punch my team partner\")\n",
        "  t.add_task(\"Drink more Orange Juice\")\n",
        "  return t\n",
        "\n",
        "def test_delete_task():\n",
        "  t = AnnoyedToDoList()\n",
        "  t = add_functions(t)\n",
        "\n",
        "  assert t.delete_task(\"\") == None"
      ],
      "metadata": {
        "id": "fGsFP42pfDGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc657e6-520a-4409-9e82-2d4d7c39cc48"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests_uebung2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest tests_uebung2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA-jXUZxl4kP",
        "outputId": "c7e3942f-f0e1-407d-988c-009854cd3353"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                                                   \u001b[0m\n",
            "\n",
            "tests_uebung2.py \u001b[32m.\u001b[0m\u001b[32m                                                                           [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Übung 2 (Optional) - Unit Test mit Mock\n",
        "\n",
        "* Die `AnnoyedTodoList` hat eine Funktion `import_tasks_from_external`\n",
        "* Diese ruft eine externe Funktion auf, welche aktuell immer eine leere Liste zurückliefert\n",
        "* Wir wollen jetzt so tun, als ob diese Methode eine Liste von extern bereitstellen würde\n",
        "* Schreibe dazu einen neuen Unit Test, in dem die Response der externen Methode `get_external_tasks` gemockt ist und prüfe das Ergebnis des Imports\n"
      ],
      "metadata": {
        "id": "igOpxNVKlWsc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHylWgPQot1z"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests_uebung2_optional.py\n",
        "from unittest.mock import patch\n",
        "from annoyed_todo_list import AnnoyedToDoList\n",
        "\n",
        "# euer Code kommt hier :)\n",
        "@patch(\"annoyed_todo_list.get_external_tasks\")\n",
        "def test_import_external_tasks():\n",
        "  mock_get_external_tasks.return_value = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
        "  t = AnnoyedToDoList()\n",
        "  t.import_tasks_from_external()\n",
        "\n",
        "  assert len(t.tasks) == 5"
      ],
      "metadata": {
        "id": "Jhn2WRrAq-pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82055adb-fd3a-4748-de08-3e6600edf2da"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests_uebung2_optional.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest tests_uebung2_optional.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or5uC44ArBDU",
        "outputId": "a88f20bb-7a59-44c1-c5be-a96d8e345392"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                                                   \u001b[0m\n",
            "\n",
            "tests_uebung2_optional.py \u001b[31mF\u001b[0m\u001b[31m                                                                  [100%]\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m____________________________________ test_import_external_tasks ____________________________________\u001b[0m\n",
            "\n",
            "args = (), keywargs = {}, newargs = (<MagicMock name='get_external_tasks' id='22535039264960'>,)\n",
            "newkeywargs = {}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mpatched\u001b[39;49;00m(*args, **keywargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.decoration_helper(patched,\u001b[90m\u001b[39;49;00m\n",
            "                                    args,\u001b[90m\u001b[39;49;00m\n",
            "                                    keywargs) \u001b[94mas\u001b[39;49;00m (newargs, newkeywargs):\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*newargs, **newkeywargs)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           TypeError: test_import_external_tasks() takes 0 positional arguments but 1 was given\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/unittest/mock.py\u001b[0m:1379: TypeError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests_uebung2_optional.py::\u001b[1mtest_import_external_tasks\u001b[0m - TypeError: test_import_external_tasks() takes 0 positional arguments but 1 was given\n",
            "\u001b[31m======================================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.16s\u001b[0m\u001b[31m =========================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Übung 3 - Linting\n",
        "\n",
        "* erstellt einen Übungs-Branch für diese Übung aus eurem Team-Branch\n",
        "* analysiert den Code der `AnnoyedToDoList`\n",
        "* diese wurde bereits in die Datei `annoyed_todo_list.py` geschrieben\n",
        "* nutzt zur `pylint` zur Code-Analyse\n",
        " * ihr findet unten eine Erklärung mit Beispiel\n",
        " * führt die Analyse wie beschrieben aus und behebt die angegebenen Issues, soweit ihr in der Zeit kommt\n",
        "* committet die Fixes in eurem Übungs-Branch\n",
        "* mergt den Übungsbranch danach wieder in euren Team-Branch"
      ],
      "metadata": {
        "id": "RQFT-Mw-fLxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to: Linting in Python\n",
        "\n",
        "Zum Linting installieren und initialisieren wir zuerst die notwendigen Python Tools:"
      ],
      "metadata": {
        "id": "B8OncaxFqlNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylint"
      ],
      "metadata": {
        "id": "IBggQVmYU3Dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2afb9427-1b13-4272-df9c-247ceee68b67"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylint in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint) (4.3.6)\n",
            "Requirement already satisfied: astroid<=3.4.0-dev0,>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from pylint) (3.3.5)\n",
            "Requirement already satisfied: isort!=5.13.0,<6,>=4.2.5 in /usr/local/lib/python3.10/dist-packages (from pylint) (5.13.2)\n",
            "Requirement already satisfied: mccabe<0.8,>=0.6 in /usr/local/lib/python3.10/dist-packages (from pylint) (0.7.0)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from pylint) (0.13.2)\n",
            "Requirement already satisfied: dill>=0.2 in /usr/local/lib/python3.10/dist-packages (from pylint) (0.3.9)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from astroid<=3.4.0-dev0,>=3.3.4->pylint) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Danach brauchen wir Python Code, den wir analysieren können. Dazu folgendes Beispiel, welches nach Ausführung als Datei abgespeichert wird."
      ],
      "metadata": {
        "id": "toULD6h1i1gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile linting_example.py\n",
        "def square_of_number(\n",
        "     num1, num2, num3,\n",
        "     num4):\n",
        "  return num1**2, num2**2, num3**3"
      ],
      "metadata": {
        "id": "6w0Voe1viQ9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941123a2-b108-4a14-8a6d-50cf50b766f3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting linting_example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Ausführung von `pylint` ist dann ganz einfach per `!pylint <Dateiname>` machbar."
      ],
      "metadata": {
        "id": "FtRWchlhjAof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pylint linting_example.py"
      ],
      "metadata": {
        "id": "wyo3mBZFU70W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41236419-a7f1-422f-f8f9-1ab27527023d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************* Module linting_example\n",
            "linting_example.py:4:0: W0311: Bad indentation. Found 2 spaces, expected 4 (bad-indentation)\n",
            "linting_example.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
            "linting_example.py:1:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "linting_example.py:3:5: W0613: Unused argument 'num4' (unused-argument)\n",
            "\n",
            "------------------------------------------------------------------\n",
            "Your code has been rated at 0.00/10 (previous run: 0.00/10, +0.00)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pylint annoyed_todo_list.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vlOve4s0RM5",
        "outputId": "88dcdcd1-98ff-4743-9cad-a1c205f14a2d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************* Module annoyed_todo_list\n",
            "annoyed_todo_list.py:17:0: W0311: Bad indentation. Found 6 spaces, expected 8 (bad-indentation)\n",
            "annoyed_todo_list.py:18:0: W0311: Bad indentation. Found 6 spaces, expected 8 (bad-indentation)\n",
            "annoyed_todo_list.py:20:0: W0311: Bad indentation. Found 6 spaces, expected 8 (bad-indentation)\n",
            "annoyed_todo_list.py:21:0: W0311: Bad indentation. Found 6 spaces, expected 8 (bad-indentation)\n",
            "annoyed_todo_list.py:72:0: W0311: Bad indentation. Found 10 spaces, expected 12 (bad-indentation)\n",
            "annoyed_todo_list.py:73:0: W0311: Bad indentation. Found 12 spaces, expected 16 (bad-indentation)\n",
            "annoyed_todo_list.py:74:0: W0311: Bad indentation. Found 12 spaces, expected 16 (bad-indentation)\n",
            "annoyed_todo_list.py:67:4: R1710: Either all return statements in a function should return an expression, or none of them should. (inconsistent-return-statements)\n",
            "\n",
            "------------------------------------------------------------------\n",
            "Your code has been rated at 8.52/10 (previous run: 8.33/10, +0.19)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Übung 3 (Optional & Fortgeschritten) - SOLID Prinzipien\n",
        "\n",
        "* schaut euch den Code der `AnnoyedTodoList` im Detail an\n",
        "* wie kann die Klasse umgebaut werden, sodass einige der SOLID Prinzipien eingehalten werden? Ein paar Tipps und Fragen dazu zur Anregung :)\n",
        " * Ist die Listenklasse aktuell für eine Aufgabe zuständig? Falls nein, wie könnte man das verbessern?\n",
        " * Kann das Verhalten der Liste aktuell einfach erweitert werden? Falls nein, wie könnte man das verbessern?\n",
        " * Macht evtl die Verwendung einer Basisklasse Sinn?\n",
        " * Könnten die Funktionalitäten der Liste aufgeteilt werden?\n",
        " * Wie könnte man die Verwendung der externen Methode `get_external_tasks` noch flexibler gestalten?\n",
        "* wie zuvor erstellt einen Übungs-Branch dazu und mergt ihn danach in den Team-Branch"
      ],
      "metadata": {
        "id": "ViZnnqihgQd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Übung 4 - Code Reviews\n",
        "\n",
        "* Stellt einen Pull Request ein, bei dem ihr euren Team-Branch auf den main Branch mergen wollt\n",
        "* Sucht euch ein anderes Team\n",
        "* führt jeweils gegenseitig ein Review auf diesem Pull Request durch und fügt Anmerkungen hinzu, die euch auffallen\n",
        "* das gesamte Notebook File ist als JSON formatiert. Deshalb wundert euch nicht, dass die Code Blöcke beim Review nicht als Python Code dargestellt.\n",
        "* tauscht euch danach gegenseitig aus"
      ],
      "metadata": {
        "id": "PLhdPSORgjtF"
      }
    }
  ]
}